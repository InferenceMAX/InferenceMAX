name: 'Test - Model Sweep'

on:
  workflow_dispatch:
    inputs:
      model:
        description: 'Model Type'
        type: choice
        required: true
        options:
          - 'LLaMA 70B'
          - 'DeepSeek R1'
          - 'gpt-oss 120B'

      run_h100:
        description: 'Test H100'
        type: boolean
        required: false

      run_h200:
        description: 'Test H200'
        type: boolean
        required: false

      run_b200:
        description: 'Test B200'
        type: boolean
        required: false

      run_mi300x:
        description: 'Test MI300X'
        type: boolean
        required: false

      run_mi325x:
        description: 'Test MI325X'
        type: boolean
        required: false

      run_mi355x:
        description: 'Test MI355X'
        type: boolean
        required: false

env:
  HF_TOKEN: ${{ secrets.HF_TOKEN }}
  HF_HUB_CACHE: '/mnt/hf_hub_cache/'
  ISL: 1024
  OSL: 1024
  MAX_MODEL_LEN: 2048
  RANDOM_RANGE_RATIO: 0.8
  TP: 8
  CONC: 4

x-common-steps:
  - &resource-cleanup:
    name: Resource cleanup
    if: ${{ matrix.config.mname == github.event.inputs.model }}
    run: |
      if command -v docker >/dev/null 2>&1; then
        echo "[Docker] Cleaning up resources ..."
        docker ps -aq | xargs -r docker rm -f
        docker network prune -f
        while [ -n "$(docker ps -aq)" ]; do
          docker ps -a
          sleep 5
        done
      fi
      if command -v squeue >/dev/null 2>&1; then
        echo "[Slurm] Cleaning up resources ..."
        scancel -u $USER
        while [ -n "$(squeue -u $USER --noheader --format='%i')" ]; do
          squeue -u $USER
          sleep 5
        done
      fi


jobs:
  bmk_h100:
    if: ${{ github.event.inputs.run_h100 }}
    strategy:
      fail-fast: false
      matrix:
        runner:
          - 'h100-cr_0'
          - 'h100-cr_1'
          - 'h100-cw_0'
          - 'h100-cw_1'
        config:
          - { 'exp-name': '70b_test', 'image': 'kedarpotdar147/vllm0.1:latest', 'model': 'nvidia/Llama-3.3-70B-Instruct-FP8' , 'mname': 'LLaMA 70B' }
          - { 'exp-name': 'gptoss_test', 'image': 'kedarpotdar147/vllm0.1:latest', 'model': 'openai/gpt-oss-120B', 'mname': 'gpt-oss 120B' }

    runs-on: ${{ matrix.runner }}
    name: '${{ matrix.config.mname }} - ${{ matrix.runner }}'

    env:
      RUNNER_NAME: ${{ matrix.runner }}
      EXP_NAME: ${{ matrix.config.exp-name }}
      IMAGE: ${{ matrix.config.image }}
      MODEL: ${{ matrix.config.model }}

    steps:
      - name: Debug step
        run: |
          echo "RUNNER_NAME=$RUNNER_NAME"
          echo "RESULT_FILENAME=${EXP_NAME}_tp${TP}_conc${CONC}_${RUNNER_NAME}"
          echo "Script filepath: /runners/launch_${RUNNER_NAME%%_*}*.sh"
          echo "github.event.inputs.model = ${{ github.event.inputs.model }}"
          echo "matrix.config.mname = ${{ matrix.config.mname }}"

      - *resource-cleanup

      - uses: actions/checkout@v3
        if: ${{ matrix.config.mname == github.event.inputs.model }}
        with:
          token: ${{ secrets.REPO_PAT }}
          fetch-depth: 0

      - name: Run benchmark script
        if: ${{ matrix.config.mname == github.event.inputs.model }}
        run: |
          echo "RESULT_FILENAME=${EXP_NAME}_tp${TP}_conc${CONC}_${RUNNER_NAME}" >> $GITHUB_ENV
          bash ./runners/launch_${RUNNER_NAME%%_*}*.sh $EXP_NAME
          if [ ! -f "$RESULT_FILENAME.json" ]; then
            echo "Run failed: Benchmark result $RESULT_FILENAME.json not found." >&2
            exit 1
          fi
