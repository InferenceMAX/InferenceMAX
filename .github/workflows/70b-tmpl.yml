name: LLaMA 70B Template

on:
  workflow_call:
    inputs:
      exp-name:
        required: true
        type: string
      isl:
        required: true
        type: string
      osl:
        required: true
        type: string
      max-model-len:
        required: true
        type: string
      random-range-ratio:
        required: true
        type: string
      timeout:
        required: false
        type: number
        default: 180

jobs:
  find-latest-image:
    runs-on: ubuntu-latest
    steps:
      - name: Find the latest Docker image
        run: echo "Hardcoding image tags for now."

  bmk-h100:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: h100
      image: 'kedarpotdar147/vllm0.1:latest'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      tp-list: '[2]'
      timeout: ${{ inputs.timeout }}
      framework: 'vllm'
      precision: ''

  bmk-h200:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: h200
      image: 'kedarpotdar147/vllm0.1:latest'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      tp-list: '[2]'  # SANITY TEST: Only TP=2
      timeout: ${{ inputs.timeout }}
      framework: 'vllm'
      precision: ''

  bmk-h200-trt:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: h200
      image: 'nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      tp-list: '[2]'  # SANITY TEST: Only TP=2
      timeout: ${{ inputs.timeout }}
      framework: 'trt'
      precision: ''

  bmk-b200:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: b200
      image: 'kedarpotdar147/vllm:05'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      tp-list: '[2]'  # SANITY TEST: Only TP=2
      timeout: ${{ inputs.timeout }}
      framework: 'vllm'
      precision: ''

  bmk-b200-trt:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: b200
      image: 'nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      tp-list: '[2]'  # SANITY TEST: Only TP=2
      timeout: ${{ inputs.timeout }}
      framework: 'trt'
      precision: ''

  # bmk-mi300x:
  #   needs: find-latest-image
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: mi300x
  #     image: 'rocm/vllm-dev:nightly_official_0729_rc1_20250718'
  #     model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
  #     tp-list: '[1, 2, 4, 8]'
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'
  #     precision: ''

  # bmk-mi325x:
  #   needs: find-latest-image
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: mi325x
  #     image: 'rocm/vllm-dev:nightly_official_0729_rc1_20250718'
  #     model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
  #     tp-list: '[2]'
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'
  #     precision: ''

  # bmk-mi355x:
  #   needs: find-latest-image
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: mi355x
  #     image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.9.1_mi35x_alpha'
  #     model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
  #     tp-list: '[2]'
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'
  #     precision: ''

  collect-results:
    needs: [bmk-h100, bmk-h200, bmk-h200-trt, bmk-b200, bmk-b200-trt] 
    if: ${{ always() && !cancelled() }}
    uses: ./.github/workflows/collect-results.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
