name: Template - LLaMA 70B

on:
  workflow_call:
    inputs:
      exp-name:
        required: true
        type: string
      isl:
        required: true
        type: string
      osl:
        required: true
        type: string
      max-model-len:
        required: true
        type: string
      random-range-ratio:
        required: true
        type: string
      timeout:
        required: false
        type: number
        default: 180

jobs:
  # bmk-h100-fp8:
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: h100
  #     image: 'kedarpotdar147/vllm0.1:latest'
  #     model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
  #     tp-list: '[2, 4, 8]'
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'
  #     precision: 'fp8'

  # bmk-h200-fp8:
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: h200
  #     image: 'kedarpotdar147/vllm0.1:latest'
  #     model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
  #     tp-list: '[1, 2, 4, 8]'
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'

  # bmk-h200-trt:
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: h200-trt
  #     image: 'nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2'
  #     model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
  #     tp-list: '[1, 2, 4, 8]'  
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'trt'

  # bmk-b200:
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: b200
  #     image: 'kedarpotdar147/vllm:05'
  #     model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
  #     tp-list: '[1, 2]'  
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'

  # bmk-b200-trt:
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: b200-trt
  #     image: 'nvcr.io#nvidia/tensorrt-llm/release:1.1.0rc2.post1'
  #     model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
  #     tp-list: '[1, 2]'  
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'trt'

  bmk-mi300x-fp8:
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: mi300x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
      tp-list: '[2]'
      timeout: ${{ inputs.timeout }}
      framework: 'vllm'
      precision: 'fp8'

  bmk-mi300x-fp4:
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: mi300x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-MXFP4-Preview'
      tp-list: '[2]'
      timeout: ${{ inputs.timeout }}
      framework: 'vllm'
      precision: 'fp4'

  # bmk-mi325x-fp8:
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: mi325x
  #     image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
  #     model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
  #     tp-list: '[1, 2, 4, 8]'
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'

  bmk-mi325x-fp4:
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: mi325x
      image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
      model: 'amd/Llama-3.3-70B-Instruct-MXFP4-Preview'
      tp-list: '[2]'
      timeout: ${{ inputs.timeout }}
      framework: 'vllm'
      precision: 'fp4'

  # bmk-mi355x-fp8:
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: mi355x
  #     image: 'rocm/7.0-preview:rocm7.0_preview_ubuntu_22.04_vllm_0.10.1_instinct_rc1'
  #     model: 'amd/Llama-3.3-70B-Instruct-FP8-KV'
  #     tp-list: '[1]'
  #     timeout: ${{ inputs.timeout }}
  #     framework: 'vllm'
