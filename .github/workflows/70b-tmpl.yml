name: LLaMA 70B Template

on:
  workflow_call:
    inputs:
      exp-name:
        required: true
        type: string
      isl:
        required: true
        type: string
      osl:
        required: true
        type: string
      max-model-len:
        required: true
        type: string
      random-range-ratio:
        required: true
        type: string
      timeout:
        required: false
        type: number
        default: 180

jobs:
  find-latest-image:
    runs-on: ubuntu-latest
    steps:
      - name: Find the latest Docker image
        run: echo "Hardcoding image tags for now."

  bmk-h100:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: h100
      image: 'kedarpotdar147/vllm0.1:latest'
      model: 'nvidia/Llama-3.1-70B-Instruct-FP8'
      tp-list: '[2, 4, 8]'
      timeout: ${{ inputs.timeout }}

  bmk-h200:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: h200
      image: 'kedarpotdar147/vllm0.1:latest'
      model: 'nvidia/Llama-3.1-70B-Instruct-FP8'
      tp-list: '[1, 2, 4, 8]'
      timeout: ${{ inputs.timeout }}

  # bmk-b200:
  #   needs: find-latest-image
  #   uses: ./.github/workflows/benchmark-tmpl.yml
  #   secrets: inherit
  #   with:
  #     exp-name: ${{ inputs.exp-name }}
  #     isl: ${{ inputs.isl }}
  #     osl: ${{ inputs.osl }}
  #     max-model-len: ${{ inputs.max-model-len }}
  #     random-range-ratio: ${{ inputs.random-range-ratio }}
  #     runner: b200
  #     image: 'kedarpotdar147/vllm0.1:latest'
  #     model: 'nvidia/Llama-3.1-70B-Instruct-FP8'
  #     tp-list: '[1, 2, 4, 8]'
  #     timeout: ${{ inputs.timeout }}

  bmk-b200-trt:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: b200-trt
      image: 'nvcr.io/nvidia/tensorrt-llm/release:1.1.0rc0'
      model: 'nvidia/Llama-3.3-70B-Instruct-FP8'
      tp-list: '[1, 2, 4, 8]'
      timeout: ${{ inputs.timeout }}

  bmk-mi300x:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: mi300x
      image: 'rocm/vllm-dev:nightly_official_0729_rc1_20250718'
      model: 'amd/Llama-3.1-70B-Instruct-FP8-KV'
      tp-list: '[1, 2, 4, 8]'
      timeout: ${{ inputs.timeout }}

  bmk-mi325x:
    needs: find-latest-image
    uses: ./.github/workflows/benchmark-tmpl.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
      isl: ${{ inputs.isl }}
      osl: ${{ inputs.osl }}
      max-model-len: ${{ inputs.max-model-len }}
      random-range-ratio: ${{ inputs.random-range-ratio }}
      runner: mi325x
      image: 'rocm/vllm-dev:nightly_official_0729_rc1_20250718'
      model: 'amd/Llama-3.1-70B-Instruct-FP8-KV'
      tp-list: '[1, 2, 4, 8]'
      timeout: ${{ inputs.timeout }}

  collect-results:
    needs: [bmk-h100, bmk-h200, bmk-b200-trt, bmk-mi300x, bmk-mi325x]
    if: ${{ always() && !cancelled() }}
    uses: ./.github/workflows/collect-results.yml
    secrets: inherit
    with:
      exp-name: ${{ inputs.exp-name }}
